{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"##########################\n# transfer learning using EfficientNetB7 as base model\n# After training, the model shows more than 85% accuracy for validation dataset.\n##########################\n\nimport numpy as np\nfrom numpy import asarray\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nfrom tensorflow.keras import optimizers\n#Use this to check if the GPU is configured correctly\nfrom tensorflow.python.client import device_lib\nfrom tensorflow.keras.applications import * #Efficient Net included here\nfrom tensorflow.keras import models\nfrom tensorflow.keras import layers\nimport glob\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import model_selection\nimport pathlib\nfrom keras.preprocessing.image import ImageDataGenerator\nimport shutil\nimport pandas as pd\nfrom tqdm import tqdm\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2022-03-07T01:17:42.002198Z","iopub.execute_input":"2022-03-07T01:17:42.002956Z","iopub.status.idle":"2022-03-07T01:17:50.526272Z","shell.execute_reply.started":"2022-03-07T01:17:42.002861Z","shell.execute_reply":"2022-03-07T01:17:50.525551Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# set parameters:  when batch_size is large, out of memory happens.\nbatch_size = 16\nimg_height = 224  #500\nimg_width = 224\nNUMBER_OF_CLASSES=10\n\n#count total number of images\ndata_dir = pathlib.Path(\"../input/vehicleImage/vehicles\")\nimage_count = len(list(data_dir.glob('*/*.JPEG')))\nprint(image_count)\n\n#The tree structure of the files can be used to compile a class_names list.\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\nprint(class_names)\nclass_id=range(len(class_names))\nprint(class_id)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:14:15.719065Z","iopub.execute_input":"2022-03-05T23:14:15.7196Z","iopub.status.idle":"2022-03-05T23:14:15.795948Z","shell.execute_reply.started":"2022-03-05T23:14:15.719556Z","shell.execute_reply":"2022-03-05T23:14:15.795086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_IMAGES_PATH = './train' \nVAL_IMAGES_PATH = './val' \nTEST_IMAGES_PATH = './test' \nExternal_DIR = '../input/vehicleImage/vehicles' \n\nos.makedirs(TRAIN_IMAGES_PATH, exist_ok = True)\nos.makedirs(VAL_IMAGES_PATH, exist_ok = True)\nos.makedirs(TEST_IMAGES_PATH, exist_ok = True)\n\n# Create directories for each class.\nfor class_id in [x for x in range(len(class_names))]:\n    os.makedirs(os.path.join(TRAIN_IMAGES_PATH, str(class_id)), exist_ok = True)\n    os.makedirs(os.path.join(VAL_IMAGES_PATH, str(class_id)), exist_ok = True)\n    os.makedirs(os.path.join(TEST_IMAGES_PATH, str(class_id)), exist_ok = True)  ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:14:29.308211Z","iopub.execute_input":"2022-03-05T23:14:29.309083Z","iopub.status.idle":"2022-03-05T23:14:29.317424Z","shell.execute_reply.started":"2022-03-05T23:14:29.309038Z","shell.execute_reply":"2022-03-05T23:14:29.316522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"directory_contents = os.listdir('./val')\nprint(directory_contents)\n\nfor item in directory_contents:\n    if os.path.isdir(item):\n        print(item)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:14:34.051217Z","iopub.execute_input":"2022-03-05T23:14:34.051757Z","iopub.status.idle":"2022-03-05T23:14:34.058399Z","shell.execute_reply.started":"2022-03-05T23:14:34.051718Z","shell.execute_reply":"2022-03-05T23:14:34.057605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# copy to train, validation and test directory\nclass_id=-1\nfor class_name in class_names:\n    class_id=class_id+1\n    Input_dir = '../input/vehicleImage/vehicles/'+class_name\n    data_dir = pathlib.Path(Input_dir)\n    image_count = len(list(data_dir.glob('*.JPEG')))\n    #print(image_count)\n    \n    #get the list of names of all the images and shuffle\n    list_ds = tf.data.Dataset.list_files( Input_dir + \"/*\", shuffle=False)\n    list_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n    \n    #Split the dataset into training, validation, and test sets :\n    slice_size = int(image_count * 0.1)\n    train_ds = list_ds.take(slice_size)\n    val_test_ds = list_ds.skip(slice_size)\n    val_ds = val_test_ds.take(slice_size)\n    test_ds = val_test_ds.skip(slice_size)\n    \n    for item in  train_ds.as_numpy_iterator():\n        shutil.copy(item.decode(\"utf-8\"), os.path.join(TRAIN_IMAGES_PATH, str(class_id)))\n\n    for item in  val_ds.as_numpy_iterator():\n        shutil.copy(item.decode(\"utf-8\"), os.path.join(VAL_IMAGES_PATH, str(class_id)))\n\n    for item in  test_ds.as_numpy_iterator():\n        shutil.copy(item.decode(\"utf-8\"), os.path.join(TEST_IMAGES_PATH, str(class_id)))\n\n    print(Input_dir)    ","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:15:20.283351Z","iopub.execute_input":"2022-03-05T23:15:20.283728Z","iopub.status.idle":"2022-03-05T23:15:44.7066Z","shell.execute_reply.started":"2022-03-05T23:15:20.283684Z","shell.execute_reply":"2022-03-05T23:15:44.705821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Options: EfficientNetB0, EfficientNetB1, EfficientNetB2, \n# EfficientNetB3,... up to  7\n# Higher the number, the more complex the model is. \n# and the larger resolutions it  can handle, but  the more GPU memory it will need\n# loading pretrained conv base model\n# input_shape is (height, width, number of channels) for images\ninput_shape=(img_height, img_width, 3)\n\nconv_base = tf.keras.applications.EfficientNetB7(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=input_shape,\n    classes=NUMBER_OF_CLASSES,\n    classifier_activation=\"softmax\"\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:16:15.298639Z","iopub.execute_input":"2022-03-05T23:16:15.299221Z","iopub.status.idle":"2022-03-05T23:16:21.824929Z","shell.execute_reply.started":"2022-03-05T23:16:15.299175Z","shell.execute_reply":"2022-03-05T23:16:21.824133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.GlobalMaxPooling2D(name=\"gap\"))\n# avoid overfitting\n# model.add(layers.Dropout(rate=0.2, name=\"dropout_out\"))\nmodel.add(layers.Dense(NUMBER_OF_CLASSES, activation=\"softmax\", name=\"fc_out\"))\nconv_base.trainable = True","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:16:40.892064Z","iopub.execute_input":"2022-03-05T23:16:40.892636Z","iopub.status.idle":"2022-03-05T23:16:42.761984Z","shell.execute_reply.started":"2022-03-05T23:16:40.892601Z","shell.execute_reply":"2022-03-05T23:16:42.761229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The ImageDataGenerator class allows us to specifiy \n# whatever augmentations we want so easily.\ntrain_datagen = ImageDataGenerator(\n    rescale=1.0 / 255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode=\"nearest\"\n)\n# Note that the validation data should not be augmented!\n# and a very important step is to normalise the images through  rescaling\ntest_datagen = ImageDataGenerator(rescale=1.0 / 255)\ntrain_generator = train_datagen.flow_from_directory(\n    # This is the target directory\n    TRAIN_IMAGES_PATH,\n    # All images will be resized to target height and width.\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    # Since we use categorical_crossentropy loss, we need categorical labels\n    class_mode=\"categorical\"\n)\nvalidation_generator = test_datagen.flow_from_directory(\n    VAL_IMAGES_PATH,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    class_mode=\"categorical\"\n)\nmodel.compile(\n    loss=\"categorical_crossentropy\",\n    optimizer=optimizers.RMSprop(learning_rate=2e-5),\n    metrics=[\"acc\"]\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:17:34.664546Z","iopub.execute_input":"2022-03-05T23:17:34.664814Z","iopub.status.idle":"2022-03-05T23:17:35.118931Z","shell.execute_reply.started":"2022-03-05T23:17:34.664785Z","shell.execute_reply":"2022-03-05T23:17:35.118188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Train the model:\nepochs=30\nNUMBER_OF_TRAINING_IMAGES=1300\nNUMBER_OF_VALIDATION_IMAGES=1300\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=NUMBER_OF_TRAINING_IMAGES // batch_size,\n    epochs=epochs,\n    validation_data=validation_generator,\n    validation_steps=NUMBER_OF_VALIDATION_IMAGES // batch_size,\n    verbose=1,\n    use_multiprocessing=True,\n    workers=4\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:18:31.759761Z","iopub.execute_input":"2022-03-05T23:18:31.760073Z","iopub.status.idle":"2022-03-05T23:19:31.748272Z","shell.execute_reply.started":"2022-03-05T23:18:31.76004Z","shell.execute_reply":"2022-03-05T23:19:31.74272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Visualize training results\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T21:56:56.994245Z","iopub.execute_input":"2022-03-05T21:56:56.994925Z","iopub.status.idle":"2022-03-05T21:56:57.30666Z","shell.execute_reply.started":"2022-03-05T21:56:56.994885Z","shell.execute_reply":"2022-03-05T21:56:57.305955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# functions that convert a file path to an (img, label) pair:\ndef get_label(file_path):\n  # Convert the path to a list of path components\n  parts = tf.strings.split(file_path, os.path.sep)\n  # The second to last is the class-directory\n  one_hot = parts[-2] == class_names\n  # Integer encode the label\n  return tf.argmax(one_hot)\n\ndef decode_img(img):\n  # Convert the compressed string to a 3D uint8 tensor\n  img = tf.io.decode_jpeg(img, channels=3)\n  # Resize the image to the desired size\n  return tf.image.resize(img, [img_height, img_width])\n\ndef process_path(file_path):\n  label = get_label(file_path)\n  # Load the raw data from the file as a string\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:05:46.431011Z","iopub.execute_input":"2022-03-05T22:05:46.431651Z","iopub.status.idle":"2022-03-05T22:05:46.438125Z","shell.execute_reply.started":"2022-03-05T22:05:46.431612Z","shell.execute_reply":"2022-03-05T22:05:46.437412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# get the list of names of all the images\ntest_ds1 = tf.data.Dataset.list_files(TEST_IMAGES_PATH+\"/*/*\", shuffle=False)\nval_ds1 = tf.data.Dataset.list_files(VAL_IMAGES_PATH+\"/*/*\", shuffle=False)\nAUTOTUNE = tf.data.AUTOTUNE\ntest_ds1 = test_ds1.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds1 = val_ds1.map(process_path, num_parallel_calls=AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T22:05:51.359465Z","iopub.execute_input":"2022-03-05T22:05:51.35973Z","iopub.status.idle":"2022-03-05T22:05:51.632662Z","shell.execute_reply.started":"2022-03-05T22:05:51.359702Z","shell.execute_reply":"2022-03-05T22:05:51.631963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict validation data\nplt.figure(figsize=(10, 10))\ni=-1\nfor image, label in val_ds1.take(15):\n    i=i+1\n    print(\"Label: \", label.numpy())\n    print(class_names[label])\n    predictions = model.predict(np.expand_dims(image/255, axis=0))\n    #score = tf.nn.softmax(predictions[0])\n    score =predictions[0]\n    print(\n        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n        .format(class_names[np.argmax(score)], 100 * np.max(score))\n    )\n    ax = plt.subplot(5, 3, i + 1)\n    plt.tight_layout(pad=1.0)\n    plt.imshow(image.numpy().astype(\"uint8\"))\n    plt.title(class_names[label] +\": :\"+ class_names[np.argmax(score)])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:06:56.851183Z","iopub.execute_input":"2022-03-05T23:06:56.851442Z","iopub.status.idle":"2022-03-05T23:07:00.785524Z","shell.execute_reply.started":"2022-03-05T23:06:56.851415Z","shell.execute_reply":"2022-03-05T23:07:00.780632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict test data\n\nplt.figure(figsize=(10, 10))\ni=-1\nfor image, label in test_ds1.take(15):\n    i=i+1\n    print(\"Label: \", label.numpy())\n    print(class_names[label])\n    predictions = model.predict(np.expand_dims(image/255, axis=0))\n    score = predictions[0]\n    print(\n        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n        .format(class_names[np.argmax(score)], 100 * np.max(score))\n    )\n    plt.tight_layout(pad=1.0)\n    ax = plt.subplot(5, 3, i + 1)\n    plt.imshow(image.numpy().astype(\"uint8\"))\n    plt.title(class_names[label] +\": :\"+ class_names[np.argmax(score)])","metadata":{"execution":{"iopub.status.busy":"2022-03-05T23:07:26.313416Z","iopub.execute_input":"2022-03-05T23:07:26.313723Z","iopub.status.idle":"2022-03-05T23:07:30.165644Z","shell.execute_reply.started":"2022-03-05T23:07:26.313691Z","shell.execute_reply":"2022-03-05T23:07:30.162388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##########################\n# Vanilla model without enhanced techniques. about 50% accuracy for validation data\n##########################","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nfrom numpy import asarray\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport glob\nimport matplotlib.pyplot as plt\nimport PIL\nfrom PIL import Image\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nimport pathlib\nfrom tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:28:12.9014Z","iopub.execute_input":"2022-03-02T15:28:12.901769Z","iopub.status.idle":"2022-03-02T15:28:19.407628Z","shell.execute_reply.started":"2022-03-02T15:28:12.901678Z","shell.execute_reply":"2022-03-02T15:28:19.406872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set parameters\nbatch_size = 32\nimg_height = 224 #224  #500\nimg_width = 224\n\n#count total number of images\ndata_dir = pathlib.Path(\"../input/vehicleImage/vehicles\")\nimage_count = len(list(data_dir.glob('*/*.JPEG')))\nprint(image_count)\n\n#get the list of names of all the images and shuffle\nlist_ds = tf.data.Dataset.list_files(\"../input/vehicleImage/vehicles/*/*\", shuffle=False)\nlist_ds = list_ds.shuffle(image_count, reshuffle_each_iteration=False)\n\n#The tree structure of the files can be used to compile a class_names list.\nclass_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\nprint(class_names)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:48:30.566638Z","iopub.execute_input":"2022-03-02T15:48:30.5669Z","iopub.status.idle":"2022-03-02T15:48:31.844782Z","shell.execute_reply.started":"2022-03-02T15:48:30.56687Z","shell.execute_reply":"2022-03-02T15:48:31.844004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split the dataset into training, validation, and test sets:\nslice_size = int(image_count * 0.3)\ntrain_ds = list_ds.take(slice_size)\nval_test_ds = list_ds.skip(slice_size)\nval_ds = val_test_ds.take(slice_size)\ntest_ds = val_test_ds.skip(slice_size)\n\nprint(tf.data.experimental.cardinality(train_ds).numpy())\nprint(tf.data.experimental.cardinality(val_ds).numpy())\nprint(tf.data.experimental.cardinality(test_ds).numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:48:38.976682Z","iopub.execute_input":"2022-03-02T15:48:38.97757Z","iopub.status.idle":"2022-03-02T15:48:39.005695Z","shell.execute_reply.started":"2022-03-02T15:48:38.977522Z","shell.execute_reply":"2022-03-02T15:48:39.004982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# functions that convert a file path to an (img, label) pair:\ndef get_label(file_path):\n  # Convert the path to a list of path components\n  parts = tf.strings.split(file_path, os.path.sep)\n  # The second to last is the class-directory\n  one_hot = parts[-2] == class_names\n  # Integer encode the label\n  return tf.argmax(one_hot)\n\ndef decode_img(img):\n  # Convert the compressed string to a 3D uint8 tensor\n  img = tf.io.decode_jpeg(img, channels=3)\n  # Resize the image to the desired size\n  return tf.image.resize(img, [img_height, img_width])\n\ndef process_path(file_path):\n  label = get_label(file_path)\n  # Load the raw data from the file as a string\n  img = tf.io.read_file(file_path)\n  img = decode_img(img)\n  return img, label","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:48:43.71486Z","iopub.execute_input":"2022-03-02T15:48:43.715769Z","iopub.status.idle":"2022-03-02T15:48:43.721862Z","shell.execute_reply.started":"2022-03-02T15:48:43.715727Z","shell.execute_reply":"2022-03-02T15:48:43.721142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Use Dataset.map to create a dataset of image, label pairs:\n# Set `num_parallel_calls` so multiple images are loaded/processed in parallel.\nAUTOTUNE = tf.data.AUTOTUNE\ntrain_ds = train_ds.map(process_path, num_parallel_calls=AUTOTUNE)\nval_ds = val_ds.map(process_path, num_parallel_calls=AUTOTUNE)\ntest_ds = test_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n\nfor image, label in train_ds.take(1):\n  print(\"Image shape: \", image.numpy().shape)\n  print(\"Label: \", label.numpy())","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:48:47.471605Z","iopub.execute_input":"2022-03-02T15:48:47.47214Z","iopub.status.idle":"2022-03-02T15:48:47.756782Z","shell.execute_reply.started":"2022-03-02T15:48:47.4721Z","shell.execute_reply":"2022-03-02T15:48:47.755341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Configure dataset for performance\n#To be well shuffled.\n#To be batched.\n#Batches to be available as soon as possible.\n\ndef configure_for_performance(ds):\n  ds = ds.cache()\n  ds = ds.shuffle(buffer_size=1000)\n  ds = ds.batch(batch_size)\n  ds = ds.prefetch(buffer_size=AUTOTUNE)\n  return ds\n\ntrain_ds = configure_for_performance(train_ds)\nval_ds = configure_for_performance(val_ds)\n\n#Visualize the data\nimage_batch, label_batch = next(iter(train_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n  label = label_batch[i]\n  plt.title(class_names[label])\n  plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:48:50.732818Z","iopub.execute_input":"2022-03-02T15:48:50.73347Z","iopub.status.idle":"2022-03-02T15:48:54.707287Z","shell.execute_reply.started":"2022-03-02T15:48:50.733426Z","shell.execute_reply":"2022-03-02T15:48:54.706525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_classes = 10\n\nmodel = tf.keras.Sequential([\n  tf.keras.layers.Rescaling(1./255),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Conv2D(32, 3, activation='relu'),\n  tf.keras.layers.MaxPooling2D(),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(128, activation='relu'),\n  tf.keras.layers.Dense(num_classes)\n])\n\nmodel.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:48:59.309589Z","iopub.execute_input":"2022-03-02T15:48:59.310613Z","iopub.status.idle":"2022-03-02T15:48:59.333781Z","shell.execute_reply.started":"2022-03-02T15:48:59.310558Z","shell.execute_reply":"2022-03-02T15:48:59.332755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training the model\nepochs=10\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:49:03.861342Z","iopub.execute_input":"2022-03-02T15:49:03.862087Z","iopub.status.idle":"2022-03-02T15:49:58.183544Z","shell.execute_reply.started":"2022-03-02T15:49:03.862038Z","shell.execute_reply":"2022-03-02T15:49:58.18281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize training results\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-02T15:50:31.818035Z","iopub.execute_input":"2022-03-02T15:50:31.818333Z","iopub.status.idle":"2022-03-02T15:50:32.119704Z","shell.execute_reply.started":"2022-03-02T15:50:31.81829Z","shell.execute_reply":"2022-03-02T15:50:32.119044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visualize the data\nimage_batch, label_batch = next(iter(val_ds))\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n    predictions = model.predict(np.expand_dims(image_batch[i], axis=0))\n    score = tf.nn.softmax(predictions[0])\n    print(\n        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n        .format(class_names[np.argmax(score)], 100 * np.max(score))\n    )\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(image_batch[i].numpy().astype(\"uint8\"))\n    label = label_batch[i]\n    plt.title(class_names[label] +\": :\"+ class_names[np.argmax(score)])\n    plt.axis(\"off\")","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:18:13.480541Z","iopub.execute_input":"2022-03-02T16:18:13.4808Z","iopub.status.idle":"2022-03-02T16:18:14.74861Z","shell.execute_reply.started":"2022-03-02T16:18:13.48077Z","shell.execute_reply":"2022-03-02T16:18:14.74798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\ni=-1\nfor image, label in test_ds.take(15):\n    i=i+1\n    print(\"Label: \", label.numpy())\n    print(class_names[label])\n    predictions = model.predict(np.expand_dims(image, axis=0))\n    score = tf.nn.softmax(predictions[0])\n    print(\n        \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n        .format(class_names[np.argmax(score)], 100 * np.max(score))\n    )\n    ax = plt.subplot(5, 3, i + 1)\n    plt.imshow(image.numpy().astype(\"uint8\"))\n    plt.title(class_names[label] +\": :\"+ class_names[np.argmax(score)])","metadata":{"execution":{"iopub.status.busy":"2022-03-02T16:18:45.474138Z","iopub.execute_input":"2022-03-02T16:18:45.474413Z","iopub.status.idle":"2022-03-02T16:18:47.629818Z","shell.execute_reply.started":"2022-03-02T16:18:45.474386Z","shell.execute_reply":"2022-03-02T16:18:47.629154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-24T22:07:07.829072Z","iopub.execute_input":"2022-02-24T22:07:07.829484Z","iopub.status.idle":"2022-02-24T22:07:07.835909Z","shell.execute_reply.started":"2022-02-24T22:07:07.829455Z","shell.execute_reply":"2022-02-24T22:07:07.835199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##########################\n# use pre-trained MobileNet without transfer learning.\n# 95.7% accuracy for Aircraft_Carrier\n# 93.2% accuracy for fireboat\n# 100% accuracy for dozen of pictires I took.\n##########################\n\nimport keras\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras.layers.core import Dense, Activation\n#from keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.applications import imagenet_utils\nfrom keras.layers import Dense,GlobalAveragePooling2D\nfrom keras.applications.mobilenet import preprocess_input\n#tf.keras.applications\nimport numpy as np\nfrom IPython.display import Image\n\n#from keras.applications import MobileNet\n","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:04:55.143599Z","iopub.execute_input":"2022-03-03T16:04:55.143865Z","iopub.status.idle":"2022-03-03T16:04:55.152336Z","shell.execute_reply.started":"2022-03-03T16:04:55.143836Z","shell.execute_reply":"2022-03-03T16:04:55.151138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mobile = tf.keras.applications.MobileNetV2()\ndef prepare_image(file):\n    img_path = ''\n    img = image.load_img(img_path + file, target_size=(224, 224))\n    img_array = image.img_to_array(img)\n    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n    return keras.applications.mobilenet.preprocess_input(img_array_expanded_dims)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:50:55.173496Z","iopub.execute_input":"2022-03-03T15:50:55.173755Z","iopub.status.idle":"2022-03-03T15:50:59.10475Z","shell.execute_reply.started":"2022-03-03T15:50:55.173727Z","shell.execute_reply":"2022-03-03T15:50:59.104064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict Aircraft_Carrier: 1244/1300=95.7%\n# get the list of names of all the images and shuffle\nlist_ds = tf.data.Dataset.list_files(\"../input/vehicleImage/vehicles/Aircraft_Carrier/*\", shuffle=False)\ncount=0\ncorrect=0\nfor f in list_ds:\n    count=count+1\n    preprocessed_image = prepare_image(f.numpy().decode(\"utf-8\"))\n    predictions = mobile.predict(preprocessed_image)\n    results = imagenet_utils.decode_predictions(predictions)\n    if results[0][0][1] == \"aircraft_carrier\" :\n        correct=correct+1\nprint(count)\nprint(correct)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:52:06.48391Z","iopub.execute_input":"2022-03-03T15:52:06.484396Z","iopub.status.idle":"2022-03-03T15:53:15.922195Z","shell.execute_reply.started":"2022-03-03T15:52:06.484359Z","shell.execute_reply":"2022-03-03T15:53:15.920664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict fireboat: 1212/1300=93.2%\n# get the list of names of all the images and shuffle                                \nlist_ds = tf.data.Dataset.list_files(\"../input/vehicleImage/vehicles/Fireboat/*\", shuffle=False)\ncount=0\ncorrect=0                                    \n                                     \ncount=0\ncorrect=0\nfor f in list_ds:\n    count=count+1\n    preprocessed_image = prepare_image(f.numpy().decode(\"utf-8\"))\n    predictions = mobile.predict(preprocessed_image)\n    results = imagenet_utils.decode_predictions(predictions)\n    if results[0][0][1] == \"fireboat\" :\n        correct=correct+1\nprint(count)\nprint(correct)","metadata":{"execution":{"iopub.status.busy":"2022-03-03T15:56:01.330684Z","iopub.execute_input":"2022-03-03T15:56:01.330936Z","iopub.status.idle":"2022-03-03T15:57:04.556987Z","shell.execute_reply.started":"2022-03-03T15:56:01.330908Z","shell.execute_reply":"2022-03-03T15:57:04.556265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_image = prepare_image('../input/vehicleImage/vehicles/Fireboat/n03344393_10001.JPEG')\npredictions = mobile.predict(preprocessed_image)\nresults = imagenet_utils.decode_predictions(predictions)\nprint(results)\nplt.imshow(preprocessed_image[0])\nplt.title(\"predicted as:\"+ results[0][0][1])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:06:18.667005Z","iopub.execute_input":"2022-03-03T16:06:18.667703Z","iopub.status.idle":"2022-03-03T16:06:18.936565Z","shell.execute_reply.started":"2022-03-03T16:06:18.667664Z","shell.execute_reply":"2022-03-03T16:06:18.935921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_image = prepare_image('../input/random/image/551eb20af2c474321f324598de76232.jpg')\npredictions = mobile.predict(preprocessed_image)\nresults = imagenet_utils.decode_predictions(predictions)\nprint(results)\nplt.imshow(preprocessed_image[0])\nplt.title(\"predicted as:\"+ results[0][0][1])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:07:40.847866Z","iopub.execute_input":"2022-03-03T16:07:40.848141Z","iopub.status.idle":"2022-03-03T16:07:41.129483Z","shell.execute_reply.started":"2022-03-03T16:07:40.848112Z","shell.execute_reply":"2022-03-03T16:07:41.128848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preprocessed_image = prepare_image('../input/random/image/f8e9ce997b5c2088926d2c157db25fa.jpg')\npredictions = mobile.predict(preprocessed_image)\nresults = imagenet_utils.decode_predictions(predictions)\nprint(results)\nplt.imshow(preprocessed_image[0])\nplt.title(\"predicted as:\"+ results[0][0][1])","metadata":{"execution":{"iopub.status.busy":"2022-03-03T16:10:12.204747Z","iopub.execute_input":"2022-03-03T16:10:12.204998Z","iopub.status.idle":"2022-03-03T16:10:12.589135Z","shell.execute_reply.started":"2022-03-03T16:10:12.204971Z","shell.execute_reply":"2022-03-03T16:10:12.588413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-02T21:27:47.870524Z","iopub.execute_input":"2022-03-02T21:27:47.870829Z","iopub.status.idle":"2022-03-02T21:27:47.939439Z","shell.execute_reply.started":"2022-03-02T21:27:47.870795Z","shell.execute_reply":"2022-03-02T21:27:47.938309Z"},"trusted":true},"execution_count":null,"outputs":[]}]}